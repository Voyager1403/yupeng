{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/05/05/hello-world/"},{"title":"","text":"pre-ICRA第一个人的实验室关注助老机器人第二个人是Caltech的phd，和Austin的zhuyifeng是朋友。机器人分三个部分，感知、规划、执行。都需要关注不确定性。’’没人用xxx方法做过xxx’’这是一个论文思路？第四个人，osu和zju，可穿戴摔倒检测美国的老年人口趋势分析第五个人yexin，亚利桑那州，场景中物体搜索任务，目标驱动视觉导航。","link":"/2021/05/15/pre-ICRA2021/"},{"title":"skill learning study","text":"Skill learning studyvideo from Peter StoneEfficient Robot Skill Learning: Grounded Simulation Learning and Imitation Learning from Observation 提出skill learning的初衷是希望用机器人打败人类足球世界杯选手 Peter Stone教授是RoboCup的主席。 RoboCup@HomeRoboCup也有家庭场景的团队，致力于service robot，使用Toyota的 HSR robot，做一些家庭任务（和人交互、取掉盖子、倒垃圾） 还有做open world reasoning，eg，在未知的世界地图里寻找一个物品。 sim2real仿真中RL练出来的policy在现实中会碰到仿真环境中没有的情况。 imitation learning inverse RL，通过demonstration找到reward。 Robot Learning. viede: The Next Generation of Robot Learning, Chelsea Finn机器人可以做很多specialist的事情，但是如果换一个门把手，或者换一个背景，就不work了。所以很intuitive的想法是给他很多场景的数据。（why not？） 如果我们想让机器对世界有更通用的理解并与之交互，那么我们需要重新思考我们的方法。 Rethinking所以有两方面可以重新思考的，一个是算法，一个是数据(能否走/imageNet的路线) 算法learn something more general than a policy. 提出了MAML 比如学习向前走（中），向后走（右）。 我们可以实现一定程度的adaption吗？确实可以一点。进一步来说，我们可以adapt to entirely new task吗？ 之前的meta-learning任务，train和test阶段的数据分布是相似的。所以我们需要可以适应更广distribution的meta-learning方法。 所以提出了新的给meta-learning用的benchmark，Meta-World。 但MAML在其上test的效果不是很好，但是为什么呢，可以发现在train的结果上也很差。 那很正常的想法是，如果试试Multi-task RL algorithm呢？结果是也很差。这到底是为什么？ 对Meta learning和MT-RL失败的分析如图有4条假设和解释，其中第四条说明了把所有task fit进一个policy很难，比一个要难很多。 所以最后我们的结论是：这是因为optimization不够好（因为网络空间很足够，但还是学不好）。 调研optimization solution为了解决前面提到的这个optimization问题，我们调查了prior literature on multi task learning。 很大一部分方法都是architectural solutions，通过改变网络框架来尝试更好的解决方案。但是没看到什么好的解决方案。 另一部分更吸引我们实验室的是change optimization process，比如如图这种是在给不同的任务加权重。但发现仍然didn’t work well for our setting。所以看起来任务的权重并不是所有问题。 所以到底怎么解决optimization的问题，我们提出了一些假设。 Hypothesis 1: Gradients from different tasks often conflict. 可以很好的解决多任务学习问题。 (?) 总结： Data现在我们关于robot的数据集都是什么样的？ 从ML的角度来看，我们的数据集和/imageNet没法比，视角少、环境少、任务也少。 从robotics角度来看，我们需要思考如何cross lab使用数据，如果可以做到，那么我们就可以做出robot的/imageNet。 RoboNet那么首先就要问，可能吗？以下是做出来的效果。 所以接下来我们要弄清楚从这样的机器人数据集中可以学到什么？： 学到下一帧图像：下面这篇文章是从一张图片去预测后面的序列，visual MPC。 测试能否泛化到其他机器人、环境上： (?) other data那我们可以使用人类的数据吗？ 因为互联网上有很多人类数据可以应用。 但是也有问题。 所以我们的第一步是imitation learning。 总结我们需要找到方法积累并使用大的数据集（无论是来自于其他实验室、还是人类），只有这样才能让robotics学科走出现在的困境，which is现在的任务都是训练在小的数据集上。 总结 open challenges有一些场景对人很简单，但是对机器人缺非常难。比如厨房，你把机器人放进去，或许这是一个他从来没见过的厨房。那么他可以在这个新环境中做燕麦粥吗？ 事实是不行，很有挑战性。 为了达到这个目标，我们需要一个可以在开放环境中根据不断搜集的数据不断学习的系统。 所以就会有很多问题，如PPT。 还有一个问题就是得知道现实环境中什么是需要discard的，不是所有环境信息都是有用的。 提问环节真的可以获取到足够广的分布的RoboNet吗？","link":"/2021/05/20/skill_learning_study/"},{"title":"teleoperation_survey","text":"teleoperationSOTA of product现在效果最好的遥操作达到了什么效果、有哪些问题需要解决？ Shadow robot2021年3月21日Shadow robotic公司公布的最新视频，视频中操作者佩戴的是HaptX Gloves（触觉反馈、手指限位），机械臂末端装配的是Shadow Dexterous Hand softbank德国航天局DisneyTowards a Natural Motion Generator: a Pipeline to Control a Humanoid based on Motion Data，2019 IROS （是否是实时？） Toyotaresearchproblem操作疲劳：由操作延迟、反复尝试导致。 关键词：motion transfer, imitation, shared autonomy, robot autonomy, intent-aware, manipulation, target-approaching intent, Motion Retargetingfor Humanoid Robots, 问题定义：real-time motion transfer with task-aware intent inference understand the human operator’s intent and provide motion assistance to achieve it 汇报草稿： 在遥操作中，接近物体的过程一直是人们关注的焦点，试图找出操作者意图操纵的物体或位置，以及如何快速的到达那里。为了推断操作者的接近意图，通常使用由操作者控制的机器人的接近轨迹。当运动轨迹向一个物体移动时，这个物体成为目标的概率将增加。","link":"/2021/05/05/teleoperation_survey-NSConflict-voyager-linux5.4.0-72-generic/"},{"title":"teleoperation_survey","text":"teleoperationSOTA of product现在效果最好的遥操作达到了什么效果、有哪些问题需要解决？ Shadow robot亚马逊AI大会 researchinterfaceMOCA(from IIT)身体前倾后仰左右倾斜控制车的移动，手的动作控制机械臂。","link":"/2021/05/05/teleoperation_survey/"},{"title":"斯坦福cs330","text":"why robots？ 人工需要付出很多努力。 现在的问题是： 现在成功的系统都可以叫做“专家系统”：学习一项任务、从头开始、并进行非常详细的监督。 所以我们需要一个更全面的体系。获得灵感的方法就是观察人类小时候是怎么学习的。人类先通过和环境交互进行学习，然后进行复杂任务的学习。所以很可能，构建更普适的学习系统也许也得这样来，建立在之前的经验上，越学越快；先学简单的，后学复杂的。 为什么需要关注深度多任务、元学习为什么需要deep不需要手工设计特征提取。 they work really well。 但是从depp learning中得到的成功模式是下图这样，但是如果我们没有大量的paired data呢？ 以及如果我们是需要long tail数据？ 如果需要快速学习知识？而不是需要从头训练？ 总结：为什么我们需要多任务、元学习以下这些问题就是原因。 what is task这非常重要。 可以依据不同的东西来区分任务。 重要的假设我们假设不同任务之间有共享特征，从而让某些算法可以提取到这些特征，进行多任务的学习。如果不具有共同特征，那还不如一个任务一个模型。 元学习像是在学习任务之间的结构，这样可以更快的学习新任务，如果任务之间没有共享结构，那么就无法比从头开始学习更快。 任务的定义所以两者的区别主要是：前者是要比分开学更好更快的学习一堆任务；后者是通过一些任务的经验，更快的学习新任务。 课堂提问：对一个单独的任务能不能使用meta-learning的方法。答案是可以的，这就更像是把一个任务进行了分类，分成了一些子任务。对一些子任务的学习会让你更好的处理新遇到的东西。 课堂提问：domain adaptation和meta learning的区别？ 多任务难道不算是一个任务吗？ 实际上可以，但是我们最好是能利用“数据来自于不同task”这个客观事实，来进行更好的利用。 why now 为什么现在研究这个主题？而不是在10年后？","link":"/2021/05/19/%E6%96%AF%E5%9D%A6%E7%A6%8FCS330%E6%B7%B1%E5%BA%A6%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%85%83%E5%AD%A6%E4%B9%A0/"}],"tags":[],"categories":[]}